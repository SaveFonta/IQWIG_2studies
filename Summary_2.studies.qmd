---
title: 'SUMMARY REPORT for new IQWiG data (restricted to 2 studies)'
author:
  - 'Saverio Fontana'
date: today
format:
  html:
      toc: true
      number-sections: true
      code-fold: true
      embed-resources: true
      smooth-scroll: true
      anchor-sections: true 
  pdf:
     toc: true
     number-sections: true
     colorlinks: true
execute:
  echo: !expr "knitr::is_html_output()"
editor: 
  markdown: 
    wrap: 72
---

```{r}
#| label: setup
#| include: false

load_libraries <- function(...) {
  pkgs <- as.character(match.call(expand.dots = FALSE)$...)
  
  for (pkg in pkgs) {
    if (!require(pkg, character.only = TRUE, quietly = TRUE)) {
      
      # 3. Se non c'è (FALSE), installalo e poi caricalo
      install.packages(pkg)
      library(pkg, character.only = TRUE, quietly = TRUE)
    }
  }
}

# Install and load required packages
if (!requireNamespace("remotes", quietly = TRUE)) {
  install.packages("remotes")
}
remotes::install_github("SaveFonta/confMeta", quiet = TRUE, upgrade = "never")

# Load all libraries
load_libraries(
  "confMeta", "bayesmeta", "dplyr", "tibble", "tidyr", 
  "ggplot2", "patchwork", "gt", "parallel", 
  "ggbeeswarm", "purrr", "ggridges"
)

# Set global theme for ggplot
theme_set(theme_minimal(base_size = 11))

```

```{r}
#| label: load-data
#| include: false

source("00_utilities.R") 

name <- "cis.rds"
inp <- file.path("Output", name)


input <- readRDS(inp)
cis <- input$cis
df_estimates <- input$df_estimates

```

# Data Overview

We are inspecting a total of **`r length(unique(df_estimates$identifier))`** meta-analysis. Those are all made up of 2 studies.

## Sheet division

Here is an overview of how many meta-analyisis are there in each Excel sheet

```{r}
a <- df_estimates %>%
   group_by(sheet_name) %>%
   summarize(n_MA = n()/2)

a %>% 
  gt() %>%
  #  Relabel Columns
  cols_label(
    sheet_name = md("**Data Sheet Name**"),
    n_MA = md("**Number of Meta-Analyses (N)**")
  )
```

## Data formatting

Another interesting fact was the way IQWIG reported the raw data. I classified them in 13 possible ways. This also show us which are the most common ways of reporting data.

-   **2x2 OR**: Binary outcome reported as a 2×2 event table (a,b,c,d); effect computed as log odds ratio from counts.

-   **2x2 RR**: Binary outcome reported as a 2×2 event table; effect computed as log risk ratio from counts.

-   **2x2 RD**: Binary outcome reported as a 2×2 event table; effect computed as risk difference from counts.

-   **HR**: Study reports the hazard ratio (or log-HR) with its standard error directly.

-   **direct OR**: Study reports the odds ratio (or log-OR) with its standard error directly.

-   **direct RR**: Study reports the risk ratio (or log-RR) with its standard error directly.

-   **direct RD**: Study reports the risk difference with its standard error directly.

-   **ROM**: Study reports the ratio of means (typically on the log scale) with its standard error directly.

-   **IDR**: Study reports the incidence density rate ratio (typically on the log scale) with its standard error directly.

-   **direct SMD**: Study reports the standardized mean difference with its standard error directly.

-   **direct MD**: Study reports the mean difference with its standard error directly.

-   **MD pooled SD**: Continuous outcome: study reports mean difference (MD), pooled SD, and group sizes (n1, n2).

-   **SMD from pooled**: Continuous outcome: study reports MD, pooled SD, and group sizes; SMD (Hedges’ g) is derived from these.

-   **singular studies MD**: Continuous outcome: study reports group means and SDs (ȳ1, s1, n1; ȳ2, s2, n2); MD is computed.

-   **singular studies SMD**: Continuous outcome: study reports SDs and group means; SMD is computed.

```{r}
df_estimates %>%
  count(data_report, .drop = FALSE)  %>%   
   arrange(desc(n)) %>% 
   gt() %>%
  # Relabel Columns
  cols_label(
    data_report = md("**How data is reported**"),
    n = md("**Number**")
  )
```

# Summary measures

This summary is computed using all the MA from above.

## Width of the confidence intervals

For each method, we summarize the distribution of **CI widths** (upper − lower) across all two-study meta-analyses.

```{r}
#| label: fig-widths
#| fig-height: 8

widths <- extract_ma_metric(cis, "width")

# Calculate summary statistics
width_summary <- widths %>%
  group_by(method) %>%
  summarise(
    mean = mean(width, na.rm = TRUE),
    sd = sd(width, na.rm = TRUE),
    median = median(width, na.rm = TRUE),
    q25 = quantile(width, 0.25, na.rm = TRUE),
    q75 = quantile(width, 0.75, na.rm = TRUE),
    min = min(width, na.rm = TRUE),
    max = max(width, na.rm = TRUE),
    .groups = "drop"
  )


width_summary %>%
  gt() %>%
  tab_header(
    title = md("**Confidence Interval Widths**"),
  ) %>%
  cols_label(
    method = "Method",
    mean = "Mean",
    sd = "SD",
    median = "Median",
    q25 = "Q25",
    q75 = "Q75",
    min = "Min",
    max = "Max"
  ) %>%
  fmt_number(
    columns = c(mean, sd, median, q25, q75, min, max),
    decimals = 2
  ) %>%
  cols_align(
    align = "center",
    columns = -method
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  opt_stylize(style = 6, color = "blue") 
```

{{< pagebreak >}}

## Confidence interval skewness

The skewness of each confidence interval is computed as:

$$
\text{Skewness} = \frac{\text{upper} + \text{lower} - 2 \times \text{estimate}}{\text{upper} - \text{lower}}
$$

```{r}
#| label: fig-skewness
#| fig-height: 7

ci_skewness <- extract_ma_metric(cis, "ci_skewness")

ci_skewness %>%
  filter(!method %in% c("Fixed effect", "Hartung & Knapp")) %>%
  group_by(method) %>%
  summarise(
    mean = mean(ci_skewness, na.rm = TRUE),
    median = median(ci_skewness, na.rm = TRUE),
    sd = sd(ci_skewness, na.rm = TRUE),
    q25 = quantile(ci_skewness, 0.25, na.rm = TRUE),
    q75 = quantile(ci_skewness, 0.75, na.rm = TRUE),
    min = min(ci_skewness, na.rm = TRUE),
    max = max(ci_skewness, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  gt() %>%
  tab_header(
    title = md("**CI Skewness**"),
  ) %>%
  cols_label(
    method = "Method",
    mean = "Mean",
    median = "Median",
    sd = "SD",
    q25 = "Q25",
    q75 = "Q75",
    min = "Min",
    max = "Max"
  ) %>%
  fmt_number(
    columns = where(is.numeric),
    decimals = 3
  ) %>% 
  cols_align(
    align = "center",
    columns = -method
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  opt_stylize(style = 6, color = "blue")
```

{{< pagebreak >}}

## Summary of Confidence Interval Coverage

How many individual study estimates fall outside their respective meta-analytic confidence intervals?

**Definitions:**

1.  **Total Estimates:** The count of individual study estimates analyzed
2.  **Outside CI (n):** Number of estimates falling outside the CI
3.  **Outside CI (%):** Percentage of estimates falling outside the CI

```{r}
#| label: coverage-analysis

# Prepare data frames
ci_df <- bind_rows(
  lapply(cis, function(x) {
    x$ci %>% 
      as.data.frame() %>% 
      mutate(n_studies = nrow(x$inputs))
  }), 
  .id = "MA"
)

est_df <- bind_rows(
  lapply(cis, function(x) {
    df <- as.data.frame(x$inputs)
    colnames(df)[1] <- "input_estimate"
    return(df)
  }), 
  .id = "MA"
)

# Merge and calculate coverage
merged_df <- merge(est_df, ci_df, by = "MA") %>%
  mutate(
    outside_CI = input_estimate < lower | input_estimate > upper
  ) %>%
  rename(method_point_estimate = estimate)

# Calculate summary statistics
coverage_summary <- merged_df %>%
  group_by(method, n_studies) %>%
  summarise(
    n_estimates_total = n(),
    n_estimates_outside = sum(outside_CI, na.rm = TRUE),
    prop_outside = n_estimates_outside / n_estimates_total,
    .groups = "drop"
  )
```

```{r}
#| label: tbl-coverage

coverage_summary %>%
  select(-( n_studies)) %>% 
  gt() %>%
  tab_header(
    title = md("**Confidence Interval Coverage Analysis**")
  ) %>%
  cols_label(
    method = "Method",
    n_estimates_total = "Total Estimates",
    n_estimates_outside = "Outside CI (n)",
    prop_outside = "Outside CI (%)"
  ) %>%
  fmt_number(
    columns = c(n_estimates_total, n_estimates_outside),
    decimals = 0,
    use_seps = TRUE
  ) %>%
  fmt_percent(
    columns = prop_outside,
    decimals = 1
  ) %>%
  cols_align(
    align = "center",
    columns = -method
  ) %>%
  data_color(
    columns = prop_outside,
    method = "numeric",
    palette = c("#ffffff", "#ffe5e5", "#ffcccc", "#ff9999"),
    domain = c(0, max(coverage_summary$prop_outside))
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_row_groups()
  ) %>%
  opt_stylize(style = 6, color = "blue")
```

{{< pagebreak >}}

## Number of significant meta-analyses

Proportion of significant *meta-analyses* by method (i.e. with intervals excluding 0).

```{r}
#| label: fig-significance
#| fig-height: 8

sign <- extract_ma_metric(cis, "significant")

get_breaks <- function(limits) {
  seq(ceiling(min(limits)), floor(max(limits)), by = 1)
}

# Create plot
sign_plot <- sign %>%
  ggplot(aes(x = method, fill = significant)) +
  facet_wrap(~n_studies, scales = "free_y", labeller = label_both) +
  geom_bar(position = "stack", alpha = 0.8) +
  scale_y_continuous(breaks = get_breaks) +
  scale_fill_manual(
    values = c("TRUE" = "#2ca02c", "FALSE" = "#d62728"),
    labels = c("TRUE" = "Significant", "FALSE" = "Not Significant")
  ) +
  labs(
    x = "Method",
    y = "Count",
    fill = "Significance"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
    panel.grid.major = element_line(color = "grey90"),
    panel.border = element_rect(color = "black", fill = NA),
    plot.title = element_text(face = "bold", size = 12),
    legend.position = "bottom"
  )

sign_plot
```

```{r}
#| label: tbl-significance

sign %>%
  group_by(method) %>%
  summarise(
    n_total = n(),
    n_significant = sum(significant == TRUE, na.rm = TRUE),
    prop_significant = n_significant / n_total,
    .groups = "drop"
  )  %>%
  gt() %>%
  tab_header(
    title = md("**Significance Statistics**"),
  ) %>%
  cols_label(
    method = "Method",
    n_total = "Total",
    n_significant = "Significant (n)",
    prop_significant = "Significant (%)"
  ) %>%
  fmt_number(
    columns = c(n_total, n_significant),
    decimals = 0
  ) %>%
  fmt_percent(
    columns = prop_significant,
    decimals = 1
  ) %>%
  cols_align(
    align = "center",
    columns = -method
  ) %>%
  data_color(
    columns = prop_significant,
    method = "numeric",
    palette = "Greens",
    domain = c(0, 1)
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_row_groups()
  ) %>%
  opt_stylize(style = 6, color = "blue")
```

## p-values (for $H_0: \theta=0$)

Distribution of method-specific p-values for testing $H_0: \theta=0$

*Note* the dashed line marks 0.05.

```{r}
pvals <- extract_ma_metric(cis, "p_0")


pvals %>%
  ggplot(aes(x = method, y = p_0, fill = method)) +
  geom_boxplot(alpha = 0.7, outlier.alpha = 0.3) +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "red", linewidth = 0.8) +
  scale_y_continuous(breaks = seq(0, 1, 0.1)) +
  labs(
    x = "Method",
    y = "p-value",
    title = "Distribution of p-values by method"
  ) +
  theme_bw() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  ) +
  coord_cartesian(ylim = c(0, 1))

```

```{r}
#| label: tbl-pvalue

pvals %>%
  group_by(method) %>%
  summarise(
    mean = mean(p_0, na.rm = TRUE),
    median = median(p_0, na.rm = TRUE),
    sd = sd(p_0, na.rm = TRUE),
    q25 = quantile(p_0, 0.25, na.rm = TRUE),
    q75 = quantile(p_0, 0.75, na.rm = TRUE),
    min = min(p_0, na.rm = TRUE),
    max = max(p_0, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  gt() %>%
  tab_header(
    title = md("**p-value Summary Statistics**")
  ) %>%
  cols_label(
    method = "Method",
    mean = "Mean",
    median = "Median",
    sd = "SD",
    q25 = "Q25",
    q75 = "Q75",
    min = "Min",
    max = "Max"
) %>%
  fmt_number(
    columns = c(mean, median, sd, q25, q75, min, max),
    decimals = 4
  )  %>%
  cols_align(
    align = "center",
    columns = -method
  ) %>%
  opt_stylize(style = 6, color = "blue")
```

### Cumulative Distribution of P-values

In this graph the **ECDF** of p-values is plotted. The grey dashed line is the CDF of the Uniform distribution.

```{r}
#| label: fig-pvalue-ecdf
#| fig-height: 7

pvals %>%
  ggplot(aes(x = p_0, color = method)) +
  stat_ecdf(geom = "step", linewidth = 1, alpha = 0.8) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", 
              color = "gray40", linewidth = 0.8) +
  annotate("text", x = 0.7, y = 0.3, 
           label = "Uniform distribution\n(under global null)", 
           color = "gray40", size = 3.5) +
  scale_x_continuous(breaks = seq(0, 1, 0.1)) +
  scale_y_continuous(breaks = seq(0, 1, 0.1)) +
  labs(
    x = "P-value",
    y = "Cumulative Probability",
    color = "Method"
    ) +
  theme_bw() +
  theme(
    legend.position = "bottom",
    legend.direction = "horizontal"
  ) +
  coord_cartesian(xlim = c(0, 1), ylim = c(0, 1))
  
```

{{< pagebreak >}}

### P-value Comparison to Fixed Effect

Now, we will compare each method's p-values with **Fixed Effect's p-values as baseline.**

```{r}
#| label: prepare-pvalue-comparison

pvals_wide <- pvals %>%
  select(MA, method, p_0) %>%
  pivot_wider(names_from = method, values_from = p_0)

# Calculate differences from Fixed Effect
only_fe <- pvals %>% 
  filter(method == "Fixed effect") %>% 
  select (MA, p_0_fe = p_0)

pvals_diff <- pvals %>% 
  left_join(
    only_fe,
    by = "MA"
  ) %>% 
  mutate (p_diff = p_0 - p_0_fe) %>% 
  filter (method != "Fixed effect")
```

Here, each panel plots the FE p-values vs the p-value of the specific method.

*Note*: if the $p_0$ were equal, points would distribute on the diagonal.

**Each point is one meta-analysis.** Points below the diagonal indicate smaller p-values than fixed effect (less conservative), and points above indicate larger p-values (more conservative).

```{r}
#| label: fig-pvalue-vs-fe
#| fig-height: 8

pvals_diff %>% 
  ggplot (aes(x = p_0_fe, y = p_0, color = method)) +
  geom_point(alpha= 0.4, size = 1.5) +
  geom_abline (intercept = 0, slope = 1, linetype = "dashed", color = "gray50", linewidth = 0.8) + 
  facet_wrap (~method) + 
  scale_x_continuous (breaks = seq(0,1, 0.2)) + 
  scale_y_continuous(breaks = seq(0,1, 0.2)) + 
  labs(
    x = "P-value (Fixed Effect)",
    y = "P-value (Method)",
    title = "Method p-values vs Fixed Effect p-values"
  ) +
  theme(
    legend.position = "none"
  )
```

{{< pagebreak >}}

### P-value Differences from Fixed Effect

This table is similar to @tbl-pvalue but with a focus on the difference $\Delta p = p_0 (method) - p_0 (FE)$ and showing the correlation between $p_0(method)$ and $p_0 (FE)$ .

```{r}
#| label: tbl-pvalue-differences

pvals_diff %>%
  group_by(method) %>%
  summarise(
    mean_diff = mean(p_diff, na.rm = TRUE),
    median_diff = median(p_diff, na.rm = TRUE),
    sd_diff = sd(p_diff, na.rm = TRUE),
    cor_with_fe = cor(p_0, p_0_fe, use = "complete.obs"),
    .groups = "drop"
  ) %>%
  gt() %>%
  tab_header(
    title = md("**P-value Differences from Fixed Effect**")
  ) %>%
  cols_label(
    method = "Method",
    mean_diff = "Mean Δ",
    median_diff = "Median Δ",
    sd_diff = "SD Δ",
    cor_with_fe = "Correlation"
  ) %>%
  fmt_number(
    columns = c(mean_diff, median_diff, sd_diff, cor_with_fe),
    decimals = 4
  ) %>%
  cols_align(
    align = "center",
    columns = -method
  ) %>%
  opt_stylize(style = 6, color = "blue")
```

{{< pagebreak >}}

### Agreement in Significance (p \< 0.05)

Here we inspect the significance agreement between the values

Each meta-analysis is classified into **four categories:** both significant, both non-significant, FE-only, or method-only.

```{r}
#| label: fig-significance-agreement
#| fig-height: 6





sign_agree_p <- pvals_diff %>% 
  group_by(method) %>% 
  mutate (
    Method_sign = p_0 <0.05,
    FE_sign = p_0_fe <0.05, 
    agreement = ifelse(FE_sign & Method_sign, "Both significant",
                       ifelse(!FE_sign & !Method_sign, "Both non-significant",
                              ifelse(FE_sign & !Method_sign, "FE sig, Method non-sig", 
                                     "FE non-sig, Method sig"))))
  
  
  
  
  

sign_agree_p %>% 
  count(method, agreement) %>% 
  ggplot(aes(x = method, y = n, fill = agreement)) + 
           geom_col (position= "stack", alpha = 0.8) + 
  geom_text(aes(label = n), position = position_stack(vjust = 0.5), size = 3,
            color = "white", fontface = "bold") + 
  scale_fill_manual ( 
    values = c(      "Both significant" = "#2ca02c",
                     "Both non-significant" = "#d62728",
                     "FE sig, Method non-sig" = "purple",
                     "FE non-sig, Method sig" = "#7f7f7f"
    )) + 
  labs (
    x = "Methods", 
    y = "Count",
    fill = "Agreement", 
    title = "Significance agreement with Fixed Effect (α = 0.05)"
  ) + 
  theme_bw() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right"
  )
  

         
```

```{r}
#| label: tbl-significance-agreement

sign_agree_p %>%
  group_by(method) %>%
  summarise(
    n_total = n(),
    both_sig = sum(FE_sign & Method_sign, na.rm = TRUE),
    both_nonsig = sum(!FE_sign & !Method_sign, na.rm = TRUE),
    fe_only = sum(FE_sign & !Method_sign, na.rm = TRUE),
    method_only = sum(!FE_sign & Method_sign, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  gt() %>%
  tab_header(
    title = md("**Significance Agreement with Fixed Effect**")
  ) %>%
  cols_label(
    method = "Method",
    n_total = "Total",
    both_sig = "Both Sig",
    both_nonsig = "Both Non-sig",
    fe_only = "FE Only",
    method_only = "Method Only",
  ) %>%
  fmt_number(
    columns = c(n_total, both_sig, both_nonsig, fe_only, method_only),
    decimals = 0
  ) %>%
  cols_align(
    align = "center",
    columns = -method
  )  %>%
  opt_stylize(style = 6, color = "blue")
```

{{< pagebreak >}}

## Coherence of skewness signs (β, γ, AUCC ratio)

Agreement between different measures of skewness:

-   **β (beta)**: CI skewness
-   **γ (gamma)**: Data skewness\
-   **AUCC ratio**: Area Under Confidence Curve ratio

where $$\gamma = \frac{\sum_{i=1}^{n} w_i (\hat{\theta} - \bar{\theta})^3}{\left( \sum_{i=1}^{n} w_i (\hat{\theta} - \bar{\theta})^2 \right)^{3/2} / \sqrt{\sum_{i=1}^{n} w_i}}$$ is Fisher’s weighted skewness coefficient.

And $$
\text{AUCC Ratio} = \frac {\text{AUCC}_{\text{upper}} - \text{AUCC}_{\text{lower}}} {AUCC}
$$.

*For more details see: Held, Leonhard, Felix Hofmann, and Samuel Pawel. "A comparison of combined p-value functions for meta-analysis." Research Synthesis Methods (2025)*

```{r}
#| label: sign-agreement-data

# Build sign agreement dataset
sign_agreement <- do.call(rbind, lapply(cis, function(x) {
  df <- x$ci 
  df <- subset(df, !is.na(ci_skewness) & !method %in% c("Fixed effect", "Hartung & Knapp", "Bayesmeta"))
  data.frame(
    MA = x$ma_id,
    method = df$method,
    data_skewness = x$data_skewness,
    ci_skewness = df$ci_skewness,
    aucc_ratio = df$aucc_ratio
  )
})) %>%
  mutate(
    same_sign_beta_gamma = sign(data_skewness) == sign(ci_skewness),
    same_sign_beta_aucc = sign(ci_skewness) == sign(aucc_ratio),
    same_sign_gamma_aucc = sign(data_skewness) == sign(aucc_ratio)
  )

```

```{r}
#| label: tbl-sign-coherence

# Calculate summary statistics
sign_summary <- sign_agreement %>%
  group_by(method) %>%
  summarise(
    n_MA = n(),
    agree_beta_gamma = sum(same_sign_beta_gamma, na.rm = TRUE),
    agree_beta_aucc = sum(same_sign_beta_aucc, na.rm = TRUE),
    agree_gamma_aucc = sum(same_sign_gamma_aucc, na.rm = TRUE),
    corr_beta_gamma = cor(ci_skewness, data_skewness, use = "complete.obs"),
    corr_beta_aucc = cor(ci_skewness, aucc_ratio, use = "complete.obs"),
    corr_gamma_aucc = cor(data_skewness, aucc_ratio, use = "complete.obs"),
    .groups = "drop"
  )

# Create gt table
sign_summary %>%
  gt() %>%
  tab_header(
    title = md("**Sign Agreement**"),
  ) %>%
  tab_spanner(
    label = md("**Sign Agreement (Count)**"),
    columns = c(agree_beta_gamma, agree_beta_aucc, agree_gamma_aucc)
  ) %>%
  tab_spanner(
    label = md("**Pearson Correlation**"),
    columns = c(corr_beta_gamma, corr_beta_aucc, corr_gamma_aucc)
  ) %>%
  cols_label(
    method = "Method",
    n_MA = md("*MA*"),
    agree_beta_gamma = "β vs γ",
    agree_beta_aucc = "β vs AUCC",
    agree_gamma_aucc = "γ vs AUCC",
    corr_beta_gamma = "β vs γ",
    corr_beta_aucc = "β vs AUCC",
    corr_gamma_aucc = "γ vs AUCC"
  ) %>%
  fmt_number(
    columns = starts_with("corr"),
    decimals = 3
  ) %>%
  fmt_number(
    columns = c(n_MA, starts_with("agree")),
    decimals = 0
  ) %>%
  sub_missing(
    columns = everything(),
    missing_text = "–"
  ) %>%
  cols_align(
    align = "center",
    columns = -method
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  opt_stylize(style = 6, color = "blue")
```

{{< pagebreak >}}

## Sign agreement among β, γ, and AUCC ratio

```{r}
#| label: fig-sign-agreement-bar
#| fig-height: 6

sign_long <- sign_agreement %>%
  filter(!method %in% c("Fixed effect", "Hartung & Knapp")) %>%
  select(MA, method, starts_with("same_sign")) %>%
  pivot_longer(
    cols = starts_with("same_sign"),
    names_to = "comparison",
    values_to = "agreement"
  ) %>%
  filter(!is.na(agreement))
  
# Create bar plot showing proportions
sign_long %>%
  mutate(
    comparison = case_when(
      comparison == "same_sign_beta_gamma" ~ "β vs γ",
      comparison == "same_sign_beta_aucc" ~ "β vs AUCC",
      comparison == "same_sign_gamma_aucc" ~ "γ vs AUCC"
    )
  ) %>%
  group_by(method, comparison) %>%
  summarise(
    prop_agree = mean(agreement, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  ggplot(aes(x = method, y = prop_agree, fill = comparison)) +
  geom_col(position = position_dodge(0.8), width = 0.7, alpha = 0.8) +
  geom_hline(yintercept = 0.5, linetype = "dashed", color = "grey30") +
  scale_y_continuous(
    labels = scales::percent_format(),
    limits = c(0, 1),
    breaks = seq(0, 1, 0.1)
  ) +
  scale_fill_manual(
    values = c("#1f77b4", "#ff7f0e", "#2ca02c")
  ) +
  labs(
    x = "Method",
    y = "Proportion of Agreement",
    fill = "Comparison"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 12),
    legend.position = "bottom"
  )
```

{{< pagebreak >}}

## Lemma 4.3.1

::: {.callout-note icon="false"}
## Lemma 4.3.1 (Two-study case)

Consider a meta-analysis with exactly two studies, with point estimates $\hat\theta_1, \hat\theta_2$ and standard errors $\sigma_1, \sigma_2 > 0$. Let the confidence level be $1-\alpha$ with $0 < \alpha < 1/4$, and define:

$$
z_{\alpha/2} := \Phi^{-1}(\alpha/2), \qquad z_{\sqrt{\alpha/4}} := \Phi^{-1}\!\left(\sqrt{\alpha/4}\right)
$$

where $\Phi^{-1}$ denotes the quantile function of the standard normal distribution. Let $\text{width}_E$ be the width of the $(1-\alpha)$-confidence interval based on the unweighted Edgington method, and $\text{width}_{FE}$ the width of the fixed-effect confidence interval.

Set $\Delta\theta := |\hat\theta_1 - \hat\theta_2|$. If at least one of the following two conditions holds, then $\text{width}_E < \text{width}_{FE}$.

**Condition 1:** $$
\frac{\max(\sigma_1,\sigma_2)}{\min(\sigma_1,\sigma_2)} \;<\; \sqrt{\left(\frac{z_{\alpha/2}}{z_{\sqrt{\alpha/4}}}\right)^2 - 1}
$$ and $$
\Delta\theta \;<\; -\,z_{\sqrt{\alpha/4}}\,\big|\sigma_2 - \sigma_1\big|
$$

**Condition 2:** $$
-\,z_{\sqrt{\alpha/4}}\,\big|\sigma_2 - \sigma_1\big| \;\le\; \Delta\theta \;<\; \frac{\sigma_1 \sigma_2}{\sqrt{\sigma_1^2 + \sigma_2^2}}\, \big(-2 z_{\alpha/2}\big) \;+\; (\sigma_1 + \sigma_2)\,z_{\sqrt{\alpha/4}}
$$
:::

```{r}
#| label: fig-lemma
#| fig-height: 8

alpha <- 0.05

# Check lemma conditions
cis_lemma <- check_lemma_conditions(cis, alpha = alpha)

# Extract and summarize results
lemma_detailed <- extract_lemma_results(cis_lemma)


lemma_applicable <- lemma_detailed %>%
  filter(applicable == TRUE)

# Plot results
plot_lemma_results(cis_lemma)
```

```{r}
#| label: tbl-lemma-summary

# Create simple summary table
lemma_summary <- lemma_applicable %>%
  summarise(
    "Total 2-Study MAs" = n(),
    "Condition 1 Holds" = sum(condition1_holds, na.rm = TRUE),
    "Condition 2 Holds" = sum(condition2_holds, na.rm = TRUE),
    "Both Conditions" = sum(condition1_holds & condition2_holds, na.rm = TRUE),
    "Neither Condition" = sum(!condition1_holds & !condition2_holds, na.rm = TRUE),
    "Edgington < FE" = sum(edgington_smaller, na.rm = TRUE),
    "Lemma Verified" = sum(lemma_verified == TRUE, na.rm = TRUE),
    "Lemma Failed" = sum(lemma_verified == FALSE, na.rm = TRUE)
  ) %>%
  pivot_longer(
    everything(),
    names_to = "Metric",
    values_to = "Count"
  ) %>%
  mutate(
    Percentage = ifelse(
      Metric == "Total 2-Study MAs",
      NA_real_,
      Count / first(Count) * 100
    )
  )

# Create table
lemma_summary %>%
  gt() %>%
  tab_header(
    title = md("**Lemma 4.3.1 Summary Statistics**"),
  ) %>%
  fmt_number(
    columns = Count,
    decimals = 0,
    use_seps = TRUE
  ) %>%
  fmt_number(
    columns = Percentage,
    decimals = 1,
    suffix = "%"
  ) %>%
  sub_missing(
    columns = Percentage,
    missing_text = "—"
  ) %>%
  cols_align(
    align = "left",
    columns = Metric
  ) %>%
  cols_align(
    align = "center",
    columns = c(Count, Percentage)
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(rows = Metric == "Total 2-Study MAs")
  ) %>%
  tab_style(
    style = cell_fill(color = "#f0f0f0"),
    locations = cells_body(rows = Metric == "Total 2-Study MAs")
  ) %>%
  opt_stylize(style = 6, color = "blue")

```

{{< pagebreak >}}

# Checking Estimates

Inspecting the Estimates (which are the point which has the highest p-value) provided by each method

```{r}

estimates_df <- extract_ma_metric(cis, "estimates")

# Calculate summary statistics
estimate_summary <- estimates_df %>%
  group_by(method) %>%
  summarise(
    mean = mean(estimates, na.rm = TRUE),
    sd = sd(estimates, na.rm = TRUE),
    median = median(estimates, na.rm = TRUE),
    q25 = quantile(estimates, 0.25, na.rm = TRUE),
    q75 = quantile(estimates, 0.75, na.rm = TRUE),
    min = min(estimates, na.rm = TRUE),
    max = max(estimates, na.rm = TRUE),
    .groups = "drop"
  )


estimate_summary %>%
  gt() %>%
  tab_header(
    title = md("**Meta Analytic estimates**"),
  ) %>%
  cols_label(
    method = "Method",
    mean = "Mean",
    sd = "SD",
    median = "Median",
    q25 = "Q25",
    q75 = "Q75",
    min = "Min",
    max = "Max"
  ) %>%
  fmt_number(
    columns = c(sd, median, q25, q75, min, max),
    decimals = 2
  ) %>%
    fmt_number(
    columns = c(mean),
    decimals = 4 
  ) %>% 
  cols_align(
    align = "center",
    columns = -method
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  opt_stylize(style = 6, color = "blue") 
```

Here, delta(Δ) = designated method - Fixed effect

```{r}

# wide: one row per MA, one column per method
wide_estimates <- estimates_df %>%
  select(MA, method, estimates) %>%
  pivot_wider(names_from = method, values_from = estimates)

# long comparison vs FE
long_vs_FE <- wide_estimates %>%
  pivot_longer(
    cols = -c(MA, `Fixed effect`),#keep FE as column so that I can compare
    names_to = "method",
    values_to = "method_est"
  ) %>%
  mutate(
    fe = `Fixed effect`,
    delta = method_est - fe,
    method_bigger_FE = method_est > `Fixed effect`,
    method_smaller_FE = method_est < `Fixed effect`,
    equal = method_est == `Fixed effect`
  ) %>% 
  select (-`Fixed effect`)



# summary table
summary_vs_FE <- long_vs_FE %>%
  group_by(method) %>%
  summarise(
    n = n(),
    pct_method_bigger_FE = mean(method_bigger_FE) * 100,
    pct_method_smaller_FE = mean(method_smaller_FE) * 100,
    pct_equal = mean(equal) * 100,
    mean_delta = mean(delta),
    mean_abs_delta = mean(abs(delta)),
    .groups = "drop"
  )


summary_vs_FE %>% 
  gt() %>%
  tab_header(
    title = md("**Meta Analytic delta-estimates**"),
  ) %>%
  cols_label(
    method = "Method",
    n = "N studies",
    pct_method_bigger_FE = "Bigger than FE (%)",
    pct_method_smaller_FE = "Smaller than FE (%)",
    pct_equal = "Equal (%)",
    mean_delta = "Mean Δ",
    mean_abs_delta = "Mean Abs Δ"
  ) %>%
  fmt_number(
    columns = c(pct_method_bigger_FE, pct_method_smaller_FE),
    decimals = 2
  ) %>%
    fmt_number(
    columns = c(mean_delta, mean_abs_delta),
    decimals = 4 
  ) %>% 
  cols_align(
    align = "center",
    columns = -method
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  opt_stylize(style = 6, color = "blue") 

```

```{r}

#COMMENTED OUT:
# Not sure if we want to inspect those studies where we have the same meta analytic estimate

#same_estimate <- wide_estimates %>% 
#  filter (Edgington == `Fixed effect`)

#list <- same_estimate$MA


#un <- unlist(list)
#same_est <- cis[un]

#extract only inputs from each elemnt of the list
#lapply(same_est, "[[" , "inputs")

```

## Agreement of sign of Estimates

Comparison of the **direction** of each method’s estimate with the **Fixed Effect** one.

For each method, we summarise how often the sign is well defined, the proportion of meta-analyses with the **same sign as FE**, the proportion with a **sign flip relative to FE**, and how often the FE estimate is near zero.

*NOTE* (values with absolute value below a small threshold `tol` are treated as near zero)

```{r}

# Sign treshold ->  If a value is smaller than this, it is not considered as a sign. VALUE CAN BE CHANGED 
tol <- 1e-6

#Better sign function w tolerance
sign3 <- function(x, tol) {
       ifelse(abs(x) <= tol, 0L, ifelse(x > 0, 1L, -1L)) 
}

long_vs_FE <- long_vs_FE %>%
  mutate(
    sign_fe = sign3(fe, tol),
    sign_method = sign3(method_est, tol),
    sign_defined = (sign_fe != 0L) & (sign_method != 0L),
    sign_agree = ifelse(sign_defined, sign_fe == sign_method, NA),
    sign_flip  = ifelse(sign_defined, sign_fe != sign_method, NA)
  )




summ_long_vs_FE <- long_vs_FE %>%
  group_by(method) %>%
  summarise(
    n_total = n(),
    n_sign_defined = sum(sign_defined, na.rm = TRUE),
    prop_same_sign = mean(sign_agree, na.rm = TRUE) *100,
    prop_flip_sign = mean(sign_flip,  na.rm = TRUE) * 100,
    prop_fe_near0 = mean(sign_fe == 0L) * 100,
    .groups = "drop"
  )


summ_long_vs_FE %>%
  gt() %>%
  tab_header(
    title = md("**Agreement of sign with Fixed Effect**")
  ) %>%
  cols_label(
    method = "Method",
    n_total = "N studies",
    n_sign_defined = "Sign defined",
    prop_same_sign = "Same sign as FE (%)",
    prop_flip_sign = "Sign flip vs FE (%)",
    prop_fe_near0 = "FE near zero (%)"
  ) %>%
  fmt_number(
    columns = c(prop_same_sign, prop_flip_sign, prop_fe_near0),
    decimals = 2
  ) %>%
  fmt_number(
    columns = c(n_total, n_sign_defined),
    decimals = 0,
    use_seps = TRUE
  ) %>%
  cols_align(
    align = "center",
    columns = -method
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  opt_stylize(style = 6, color = "blue")


```

## Shrinkage ratio

\$SR = \\hat{\\mu}\_{\\text{method}} / \\hat{\\mu}\_{\\text{FE}}\$

Negative values of SR indicate a **sign flip** relative to FE, while positive values indicate agreement in direction. Among positive ratios, values between 0 and 1 correspond to **shrinkage toward zero** relative to FE, and values larger than 1 indicate **more extreme estimates** than FE.

For each method, we report how often estimates flip sign, how often they are shrunken toward zero, how often they are more extreme than FE.

```{r}

# ---- SHRINKAGE RATIO SR = method / FE ----

ratio_df <- long_vs_FE %>%
  mutate(
    SR = method_est / fe,                     #  shrinkage ratio
    SR_class = case_when(
      SR < 0 ~ "Flip sign (SR<0)",
      SR >= 0 & SR < 1 ~ "Shrink toward 0 (0<=SR<1)",
      SR == 1 ~ "Equal (SR=1)",
      SR > 1 ~ "More extreme (SR>1)"
      )
  )

ratio_summary <- ratio_df %>%
  group_by(method) %>%
  summarise(
    n = n(),
    prop_flip = mean(SR < 0, na.rm = TRUE) *100,
    prop_shrink = mean(SR >= 0 & SR < 1, na.rm = TRUE) *100,
    prop_more_extreme = mean(SR > 1, na.rm = TRUE) * 100,
    .groups = "drop"
  )

ratio_summary %>% 
  gt() %>%
  tab_header(
    title = md("**Shrinkage ratio summary**"),
  ) %>%
  cols_label(
    method = "Method",
    n = "N studies",
    prop_flip = "Flipped signs (%)",
    prop_shrink = "Shrinked estimates(%)",
    prop_more_extreme = "More extreme estimates (%)"
    ) %>%
  fmt_number(
    columns = c(prop_flip, prop_shrink, prop_more_extreme),
    decimals = 2
  ) %>% 
  cols_align(
    align = "center",
    columns = -method
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) %>%
  opt_stylize(style = 6, color = "blue") 

```
